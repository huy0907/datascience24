{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNb8E9aLWLlpGUGcBMO6H/d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huy0907/datascience24/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UkGfj9p0vpN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFG0WTMd0xQt"
      },
      "source": [
        "bbc = pd.read_csv('https://raw.githubusercontent.com/dhminh1024/practice_datasets/master/bbc-text.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vkqU_7L03OZ",
        "outputId": "28361034-4947-480d-9b5b-1c14313fafc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "bbc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K33GfF104vU",
        "outputId": "c9af9829-c8ba-4dac-b0fa-5f63dea80d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "vocab = Counter()\n",
        "for text in bbc.text:\n",
        "    for word in text.split(' '):\n",
        "        vocab[word] += 1\n",
        "\n",
        "vocab.most_common(20)\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "vocab_reduced = Counter()\n",
        "\n",
        "for w, c in vocab.items():\n",
        "    if not w in stop_words:\n",
        "        vocab_reduced[w]=c\n",
        "\n",
        "vocab_reduced.most_common(50)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 65553),\n",
              " ('said', 5072),\n",
              " ('-', 3195),\n",
              " ('mr', 2992),\n",
              " ('would', 2574),\n",
              " ('also', 2154),\n",
              " ('people', 1970),\n",
              " ('new', 1957),\n",
              " ('us', 1786),\n",
              " ('one', 1705),\n",
              " ('could', 1509),\n",
              " ('said.', 1499),\n",
              " ('year', 1396),\n",
              " ('last', 1380),\n",
              " ('first', 1277),\n",
              " ('.', 1171),\n",
              " ('two', 1161),\n",
              " ('government', 1085),\n",
              " ('world', 1076),\n",
              " ('uk', 993),\n",
              " ('time', 982),\n",
              " ('make', 919),\n",
              " ('best', 912),\n",
              " ('told', 900),\n",
              " ('get', 883),\n",
              " ('made', 835),\n",
              " ('like', 830),\n",
              " ('many', 825),\n",
              " ('film', 793),\n",
              " ('years', 770),\n",
              " ('labour', 769),\n",
              " ('next', 767),\n",
              " ('music', 765),\n",
              " ('number', 748),\n",
              " ('three', 742),\n",
              " ('bbc', 734),\n",
              " ('take', 732),\n",
              " ('back', 731),\n",
              " ('game', 727),\n",
              " ('000', 708),\n",
              " ('said:', 682),\n",
              " ('way', 673),\n",
              " ('set', 673),\n",
              " ('company', 645),\n",
              " ('well', 635),\n",
              " ('may', 630),\n",
              " ('good', 621),\n",
              " ('still', 620),\n",
              " ('going', 614),\n",
              " ('home', 601)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSUJ79n01Ak2"
      },
      "source": [
        "import re\n",
        "\n",
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
        "    \n",
        "    return text\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = bbc['text']\n",
        "y = bbc['category']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=102)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf_U67ui1PZh",
        "outputId": "1b619bca-4091-436e-8b2b-5ad5dbed288f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=stop_words,\n",
        "                        tokenizer=tokenizer_porter,\n",
        "                        preprocessor=preprocessor)\n",
        "\n",
        "clf = Pipeline([('vect', tfidf),\n",
        "                ('clf', RandomForestClassifier(max_depth= 10, random_state=0))])\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=<function preprocessor at 0x7f75fbb64730>,\n",
              "                                 smooth_idf=True,\n",
              "                                 stop_words=['i', 'me', 'my', 'myself', '...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=10, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=0,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjawUD1a1QvT",
        "outputId": "fba4fc2b-3c88-4e29-b979-6dd284e86dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "predictions = clf.predict(X_test)\n",
        "print('accuracy:',accuracy_score(y_test,predictions))\n",
        "print('confusion matrix:\\n',confusion_matrix(y_test,predictions))\n",
        "print('classification report:\\n',classification_report(y_test,predictions))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9370786516853933\n",
            "confusion matrix:\n",
            " [[87  0  1  1  1]\n",
            " [ 7 78  0  7  0]\n",
            " [ 3  0 78  4  0]\n",
            " [ 1  0  0 98  0]\n",
            " [ 1  0  1  1 76]]\n",
            "classification report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     business       0.88      0.97      0.92        90\n",
            "entertainment       1.00      0.85      0.92        92\n",
            "     politics       0.97      0.92      0.95        85\n",
            "        sport       0.88      0.99      0.93        99\n",
            "         tech       0.99      0.96      0.97        79\n",
            "\n",
            "     accuracy                           0.94       445\n",
            "    macro avg       0.94      0.94      0.94       445\n",
            " weighted avg       0.94      0.94      0.94       445\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p419O-es1R7G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}